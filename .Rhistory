plot(df, col = cl.1000$cluster)
points(cl.1000$centers, col = 1:5, pch = 8)
x<- rbind(matrix(rnorm(70000, sd = 0.3), ncol = 2),matrix(rnorm(70000, mean = 1, sd = 0.3),ncol = 2))
colnames(x) <- c("x", "y")
cl<- kmeans(x, 1000, iter.max=20)
plot(cl$centers)
cah <- hclust(dist(cl$centers))#,"complete")#, graph=FALSE, nb.clust=-1)
plot(cah)
clustering_data<- rxImport(inData = x)
x
clustering_data<- rxImport(inData = inputFile)
inputFile
lym<-read.table(inputFile)
fileP<-"/home/animeshs/Downloads/"
fileN<-"Sel66.txt"
inputFile <- paste0(fileP, fileN)
lym<-read.table(inputFile)
lym
clustering_data<- rxImport(inData = inputFile)
View(cl)
View(clustering_data)
rxGetVarInfo(clustering_data)
z<-rxKmeans(~ 1_19912 + 9_1702, data =clustering_data, numClusters = 3, maxIterations=100)
z<-rxKmeans(~1_19912 + ~9_1702, data =clustering_data, numClusters = 3, maxIterations=100)
lym<-read.table(inputFile,row.names = 1)
lym
cl<- kmeans(lym, 1000, iter.max=20)
lym<-read.table(inputFile,row.names = 1)
cl<- kmeans(lym, 1000, iter.max=20)
cl<- kmeans(lym, 10, iter.max=20)
clustering_data<- rxImport(inData = "/home/animeshs/Downloads/dataClustering.csv")
rxGetVarInfo(clustering_data)
z<-rxKmeans(~Coord_X + Coord_Y, data =clustering_data, numClusters = 3, maxIterations=100)
clustering_data<- rxImport(inData = "/home/animeshs/Downloads/dataClustering.csv")
rxGetVarInfo(clustering_data)
clustering_data
z<-rxKmeans(~V189 + V190, data =clustering_data, numClusters = 3, maxIterations=100)
rxGetVarInfo(clustering_data)
z<-rxKmeans(~V189 + V188, data =clustering_data, numClusters = 3, maxIterations=100)
clustering_data
View(clustering_data)
clustering_data<- rxImport(inData = "/home/animeshs/Downloads/dataClustering.csv")
clustering_data
lym<-read.table(inputFile,row.names = 1,header = T)
lym
summary(lym)
clustering_data<-data.frame(lym)
rxGetVarInfo(clustering_data)
z<-rxKmeans(~X9_1702 + X8_16846, data =clustering_data, numClusters = 3, maxIterations=100)
rxKmeans(as.formula(paste("~",paste(names(clustering_data),collapse="+"))),data = clustering_data, numClusters = 3, maxIterations=100)
z<-rxKmeans(as.formula(paste("~",paste(names(clustering_data),collapse="+"))),data = clustering_data, numClusters = 3, maxIterations=100)
z
plot(z)
plot(z$centers)
plot(DF, col = z$cluster)
plot(clustering_data, col = z$cluster)
points(z$centers, col = 1:5, pch = 8)
plot(clustering_data, col = z$cluster)
points(z$centers, col = 1:5, pch = 8)
z$centers
points(z$centers, col = 1:5, pch = 8)
mat <- matrix(data = rnorm(300, mean= 100,sd=10), nrow = 150, ncol = 2)
mat.dist<-as.matrix(dist(mat))
heatmap(mat.dist,Colv=NA, Rowv=NA, scale="none")
colorScale <- colorRampPalette(c("blue","green","yellow","red","darkred"))(1000)
heatmap(mat.dist,Colv=NA, Rowv=NA,scale="none",col=colorScale)
#install.packages("mclust")
library("mclust")
?mclustBIC
?Mclust
summary(lym)
lym[is.na(lym)]=0
BIC <- mclustBIC(lym)
plot(BIC)
summary(BIC)
mod1 <- Mclust(lym, x = BIC)
summary(mod1, parameters = TRUE)
plot(mod1, what = "classification")
#install.packages("mclust")
library("mclust")
?mclustBIC
?Mclust
fileP<-"/home/animeshs/Downloads/"
fileN<-"Sel66.txt"
inputFile <- paste0(fileP, fileN)
lym<-read.table(inputFile,row.names = 1,header=T)
summary(lym)
lym[is.na(lym)]=0
BIC <- mclustBIC(lym)
plot(BIC)
summary(BIC)
mod1 <- Mclust(lym, x = BIC)
summary(mod1, parameters = TRUE)
plot(mod1, what = "classification")
pcaD<-prcomp(lym, center = TRUE, scale. = FALSE)
summary(pcaD)
plot(pca$x)
plot(pcaD$x)
library(MASS)
data(iris)
head(iris, 3)
train <- sample(1:150, 75)
r <- lda(formula = Species ~ .,data = iris,prior = c(1,1,1)/3,subset = train)
r$prior
r$counts
#means for each covariate
r$means
#with 3 classes we have at most two linear discriminants
r$scaling
#the singular values (svd) that gives the ratio of the between- and within-group standard deviations on the linear discriminan variables.
r$svd
# amount of the between-group variance that is explained by eaclinear discriminant
prop = r$svd^2/sum(r$svd^2)
head(r2$class)
head(r$class)
head(prop$class)
plda = predict(object = r, newdata = iris[-train, ])
plda
install.packages("devtools")
install.packages("devtools")
devtools::install_github("rstudio/keras")
install.packages("devtools")
devtools::install_github("rstudio/keras")
install.packages("devtools")
install.packages("devtools")
?kmeans
library(keras)
install.packages("devtools")
devtools::install_github("rstudio/keras")
library(keras)
install_keras()
library(keras)
install.packages("rpart")
install.packages("rpart.plot")
install.packages("randomForest")
#install.packages("devtools")
#devtools::install_github("rstudio/keras")
library(keras)
#install_keras()
use_session_with_seed(3)
data(iris)
head(iris, 3)
summary(iris)
plot(iris)
install.packages("ggplot2")
install.packages("ggfortify")
#install.packages("ggplot2")
#install.packages("ggfortify")
log.iris=log(iris[,1:4])
iris.pca=prcomp(log.iris,center=TRUE,scale.=TRUE)
autoplot(iris.pca,data=iris,colour='Species',main="PCA of the iris dataset")
library("ggplot2")
autoplot(iris.pca,data=iris,colour='Species',main="PCA of the iris dataset")
#install.packages("ggplot2")
#install.packages("ggfortify")
library("ggfortify")
log.iris=log(iris[,1:4])
iris.pca=prcomp(log.iris,center=TRUE,scale.=TRUE)
library("ggplot2")
autoplot(iris.pca,data=iris,colour='Species',main="PCA of the iris dataset")
plot(iris$Sepal.Length,iris$Sepal.Width,pch=21,bg=c("red","green3","blue")[unclass(iris$Species)],xlab="Sepal Length",ylab="Sepal Width")
autoplot(iris.pca,data=iris,colour='Species',main="PCA of the iris dataset")
plot(iris$Sepal.Length,iris$Sepal.Width,pch=21,bg=c("red","green3","blue")[unclass(iris$Species)],xlab="Sepal Length",ylab="Sepal Width")
plot(iris$Petal.Length,iris$Petal.Width,pch=21,bg=c("red","green3","blue")[unclass(iris$Species)],xlab="Petal Length",ylab="Petal Width")
iris[,5]=as.numeric(iris[,5])-1
iris=as.matrix(iris)
dimnames(iris)=NULL
iris[,5]=as.numeric(iris[,5])-1
iris=as.matrix(iris)
dimnames(iris)
data(iris)
data(iris)
iris[,5]=as.numeric(iris[,5])-1
iris=as.matrix(iris)
dimnames(iris)
dimnames(iris)=NULL
set.seed(2)
ind=sample(2,nrow(iris),replace=TRUE,prob=c(0.80,0.20))
iris.training=iris[ind==1,1:4]
iris.test=iris[ind==2,1:4]
iris.trainingtarget=iris[ind==1,5]
iris.testtarget=iris[ind==2,5]
iris.trainLabels=to_categorical(iris.trainingtarget)
iris.testLabels=to_categorical(iris.testtarget)
model=keras_model_sequential()
model
model=keras_model_sequential()
model %>%
layer_dense(input_shape=c(4),units=8,activation='relu',kernel_initializer="glorot_normal",use_bias=TRUE) %>%
layer_dense(units=3,activation='softmax',kernel_initializer="glorot_normal",use_bias=TRUE)
model
summary(model)
model %>% compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')
history=model %>% fit(iris.training,iris.trainLabels,epochs=200,batch_size=5,validation_split=0.2)
plot(history)
history=model %>% fit(iris.training,iris.trainLabels,epochs=1000,batch_size=5,validation_split=0.2)
plot(history)
predicted.classes=model %>% predict_classes(iris.test)
table(iris.testtarget,predicted.classes)
score=model %>% evaluate(iris.test,iris.testLabels)
print(score)
model=keras_model_sequential()
model %>%
layer_dense(input_shape=c(4),units=28,activation='relu',kernel_initializer="glorot_normal",use_bias=TRUE) %>%
layer_dense(units=3,activation='softmax',kernel_initializer="glorot_normal",use_bias=TRUE)
model %>% compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')
model %>% fit(iris.training,iris.trainLabels,epochs=200,batch_size=5,validation_split=0.2)
score=model %>% evaluate(iris.test,iris.testLabels)
print(score)
model=keras_model_sequential()
model %>%
layer_dense(input_shape=c(4),units=28,activation='relu',kernel_initializer="glorot_normal",use_bias=TRUE) %>%
layer_dense(units=5,activation='relu',kernel_initializer="glorot_normal",use_bias=TRUE) %>%
layer_dense(units=3,activation='softmax',kernel_initializer="glorot_normal",use_bias=TRUE)
model %>% compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')
model %>% fit(iris.training,iris.trainLabels,epochs=200,batch_size=5,validation_split=0.2)
score=model %>% evaluate(iris.test,iris.testLabels)
print(score)
fileP<-"/home/animeshs/Downloads/"
fileN<-"Sel66.txt"
inputFile <- paste0(fileP, fileN)
lym<-read.table(inputFile,row.names = 1, header=T)
fileC<-"Code.txt"
lym<-read.table(paste0(fileP, fileN),row.names = 1, header=T)
lym
fileC<-"Code.txt"
code<-read.table(paste0(fileP, fileC),row.names = 1, header=T)
code
iris
summary(lym)
lym[is.na(lym)]=0
summary(lym)
data(iris)
iris
iris[,5]
as.numeric(iris[,5])-1
as.numeric(iris[,5])
as.numeric(iris[,5])-1
install.packages('quantable')
fileP<-"/home/animeshs/Downloads/"
fileN<-"Sel66.txt"
lym<-read.table(paste0(fileP, fileN),row.names = 1, header=T)
fileC<-"Code.txt"
code<-read.table(paste0(fileP, fileC),row.names = 1, header=T)
summary(lym)
library(quantable)
y<-lym
y=robustscale(y)
y$data
y$data[is.na(y$data)]<-0
names(y$data)=sub("X","",names(y$data))
install.packages('dplyr')
install.packages("dplyr")
colnames(y$data)
code$Code2
code$Code
yy<-rbind(y$data,code$Code)
yy
View(yy)
yy<-t(yy)
yy
yy<-rbind(y$data,code$Code)
summary(yy)
yy<-rbind(y$data,code$Code)
View(yy)
t(as.numeric(yy[67,])-1)
yyt=t(as.numeric(yy[67,])-1)
summary(yyt)
yyt<-t(yy)
yyt=t(as.numeric(yy[67,])-1)
yyt<-t(yy)
yyt<-t(yy)
yyt<-t(yy)
summary(yy)
summary(yy)
yy<-rbind(y$data,code$Code)
yy
View(yy)
yyt<-t(yy)
summary(yyt)
as.numeric(yyt[,67])-1
yyt[,67]=as.numeric(yyt[,67])-1
summary(yyt)
iris=as.matrix(yyt)
dimnames(iris)=NULL
set.seed(2)
ind=sample(2,nrow(iris),replace=TRUE,prob=c(0.80,0.20))
iris.training=iris[ind==1,1:4]
iris.test=iris[ind==2,1:4]
iris.trainingtarget=iris[ind==1,5]
iris.testtarget=iris[ind==2,5]
iris.trainLabels=to_categorical(iris.trainingtarget)
iris.testLabels=to_categorical(iris.testtarget)
library(keras)
#install_keras()
use_session_with_seed(3)
set.seed(2)
ind=sample(2,nrow(iris),replace=TRUE,prob=c(0.80,0.20))
iris.training=iris[ind==1,1:4]
iris.test=iris[ind==2,1:4]
iris.trainingtarget=iris[ind==1,5]
iris.testtarget=iris[ind==2,5]
iris.trainLabels=to_categorical(iris.trainingtarget)
iris.trainLabels=to_categorical(iris.trainingtarget)
iris.testLabels=to_categorical(iris.testtarget)
model=keras_model_sequential()
model %>%
layer_dense(input_shape=c(4),units=8,activation='relu',kernel_initializer="glorot_normal",use_bias=TRUE) %>%
layer_dense(units=3,activation='softmax',kernel_initializer="glorot_normal",use_bias=TRUE)
summary(model)
model %>% compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')
history=model %>% fit(iris.training,iris.trainLabels,epochs=1000,batch_size=5,validation_split=0.2)
iris.testLabels
iris.trainLabels
model %>% compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')
history=model %>% fit(iris.training,iris.trainLabels,epochs=1000,batch_size=5,validation_split=0.2)
iris.trainLabels=to_categorical(iris.trainingtarget)
iris.testLabels=to_categorical(iris.testtarget)
iris.trainLabels
iris.testLabels
iris
View(iris)
fileP<-"/home/animeshs/Downloads/"
fileN<-"Sel66.txt"
lym<-read.table(paste0(fileP, fileN),row.names = 1, header=T)
fileC<-"Code.txt"
code<-read.table(paste0(fileP, fileC),row.names = 1, header=T)
summary(lym)
library(quantable)
y<-lym
y=robustscale(y)
y$data[is.na(y$data)]<-0
names(y$data)=sub("X","",names(y$data))
colnames(y$data)
yy<-rbind(y$data,code$Code)
yyt<-t(yy)
summary(yyt)
iris.testLabels
fileP<-"/home/animeshs/Downloads/"
fileN<-"Sel66.txt"
lym<-read.table(paste0(fileP, fileN),row.names = 1, header=T)
fileC<-"Code.txt"
code<-read.table(paste0(fileP, fileC),row.names = 1, header=T)
summary(lym)
library(quantable)
y<-lym
y=robustscale(y)
y$data[is.na(y$data)]<-0
names(y$data)=sub("X","",names(y$data))
colnames(y$data)
yy<-rbind(y$data,code$Code)
yyt<-t(yy)
summary(yyt)
yyt[,67]=as.numeric(yyt[,67])-1
summary(yyt)
yyt=as.matrix(yyt)
dimnames(yyt)=NULL
library(keras)
#install_keras()
use_session_with_seed(3)
set.seed(2)
ind=sample(2,nrow(yyt),replace=TRUE,prob=c(0.80,0.20))
yyt.training=yyt[ind==1,1:4]
yyt.test=yyt[ind==2,1:4]
yyt.trainingtarget=yyt[ind==1,5]
yyt.testtarget=yyt[ind==2,5]
yyt.trainLabels=to_categorical(yyt.trainingtarget)
yyt.testLabels=to_categorical(yyt.testtarget)
model=keras_model_sequential()
model %>%
layer_dense(input_shape=c(4),units=8,activation='relu',kernel_initializer="glorot_normal",use_bias=TRUE) %>%
layer_dense(units=3,activation='softmax',kernel_initializer="glorot_normal",use_bias=TRUE)
summary(model)
model %>% compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')
history=model %>% fit(yyt.training,yyt.trainLabels,epochs=1000,batch_size=5,validation_split=0.2)
plot(history)
predicted.classes=model %>% predict_classes(yyt.test)
table(yyt.testtarget,predicted.classes)
iris.testLabels
table(yyt.testtarget,predicted.classes)
table(yyt.testtarget,predicted.classes)
model=keras_model_sequential()
model %>%
layer_dense(input_shape=c(4),units=8,activation='relu',kernel_initializer="glorot_normal",use_bias=TRUE) %>%
layer_dense(units=3,activation='softmax',kernel_initializer="glorot_normal",use_bias=TRUE)
summary(model)
model %>% compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')
history=model %>% fit(yyt.training,yyt.trainLabels,epochs=1000,batch_size=5,validation_split=0.2)
model=keras_model_sequential()
model %>%
layer_dense(input_shape=c(4),units=28,activation='relu',kernel_initializer="glorot_normal",use_bias=TRUE) %>%
layer_dense(units=3,activation='softmax',kernel_initializer="glorot_normal",use_bias=TRUE)
model %>% compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')
model %>% fit(iris.training,iris.trainLabels,epochs=200,batch_size=5,validation_split=0.2)
score=model %>% evaluate(iris.test,iris.testLabels)
print(score)
model=keras_model_sequential()
model %>%
layer_dense(input_shape=c(4),units=28,activation='relu',kernel_initializer="glorot_normal",use_bias=TRUE) %>%
layer_dense(units=5,activation='relu',kernel_initializer="glorot_normal",use_bias=TRUE) %>%
layer_dense(units=3,activation='softmax',kernel_initializer="glorot_normal",use_bias=TRUE)
model %>% compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')
model %>% fit(iris.training,iris.trainLabels,epochs=200,batch_size=5,validation_split=0.2)
score=model %>% evaluate(iris.test,iris.testLabels)
print(score)
#install.packages("devtools")
#devtools::install_github("rstudio/keras")
library(keras)
#install_keras()
use_session_with_seed(3)
data(iris)
head(iris, 3)
summary(iris)
plot(iris)
#install.packages("ggplot2")
#install.packages("ggfortify")
library("ggfortify")
log.iris=log(iris[,1:4])
iris.pca=prcomp(log.iris,center=TRUE,scale.=TRUE)
library("ggplot2")
autoplot(iris.pca,data=iris,colour='Species',main="PCA of the iris dataset")
plot(iris$Sepal.Length,iris$Sepal.Width,pch=21,bg=c("red","green3","blue")[unclass(iris$Species)],xlab="Sepal Length",ylab="Sepal Width")
plot(iris$Petal.Length,iris$Petal.Width,pch=21,bg=c("red","green3","blue")[unclass(iris$Species)],xlab="Petal Length",ylab="Petal Width")
data(iris)
iris[,5]=as.numeric(iris[,5])-1
iris=as.matrix(iris)
dimnames(iris)=NULL
set.seed(2)
ind=sample(2,nrow(iris),replace=TRUE,prob=c(0.80,0.20))
iris.training=iris[ind==1,1:4]
iris.test=iris[ind==2,1:4]
iris.trainingtarget=iris[ind==1,5]
iris.testtarget=iris[ind==2,5]
iris.trainLabels=to_categorical(iris.trainingtarget)
iris.testLabels=to_categorical(iris.testtarget)
model=keras_model_sequential()
model %>%
layer_dense(input_shape=c(4),units=8,activation='relu',kernel_initializer="glorot_normal",use_bias=TRUE) %>%
layer_dense(units=3,activation='softmax',kernel_initializer="glorot_normal",use_bias=TRUE)
summary(model)
model %>% compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')
history=model %>% fit(iris.training,iris.trainLabels,epochs=100,batch_size=5,validation_split=0.2)
plot(history)
predicted.classes=model %>% predict_classes(iris.test)
table(iris.testtarget,predicted.classes)
score=model %>% evaluate(iris.test,iris.testLabels)
print(score)
View(iris)
View(iris.pca)
View(iris)
View(yyt)
View(yyt)
summary(yyt)
summary(iris)
summary(yyt)
yyt[,67]=as.numeric(yyt[,67]-1)
summary(yyt)
yyt[,67]=floor(yyt[,67]-1)
summary(iris)
summary(yyt)
yyt=as.matrix(yyt)
dimnames(yyt)=NULL
summary(yyt)
yyt[,67]=as.integer(yyt[,67]-1)
summary(iris)
summary(yyt)
summary(iris)
yyt[,67]=as.number(yyt[,67]-1)
yyt[,67]=as.numeric(yyt[,67]-1)
summary(iris)
summary(yyt)
summary(iris)
ind=sample(2,nrow(yyt),replace=TRUE,prob=c(0.80,0.20))
ind
yyt.training=yyt[ind==1,1:66]
yyt.test=yyt[ind==2,1:66]
yyt.trainingtarget=yyt[ind==1,5]
yyt.training=yyt[ind==1,1:66]
yyt[,67]=as.numeric(yyt[,67]-1)
yyt<-t(yy)
yyt<-t(yy)
summary(yyt)
yyt[,67]=as.numeric(yyt[,67]-1)
summary(iris)
summary(yyt)
yyt=as.matrix(yyt)
dimnames(yyt)=NULL
library(keras)
ind=sample(2,nrow(yyt),replace=TRUE,prob=c(0.80,0.20))
yyt.training=yyt[ind==1,1:66]
yyt.test=yyt[ind==2,1:66]
yyt.trainingtarget=yyt[ind==1,67]
yyt.testtarget=yyt[ind==2,67]
yyt.trainLabels=to_categorical(yyt.trainingtarget)
yyt.testLabels=to_categorical(yyt.testtarget)
model=keras_model_sequential()
model %>%
layer_dense(input_shape=c(4),units=8,activation='relu',kernel_initializer="glorot_normal",use_bias=TRUE) %>%
layer_dense(units=3,activation='softmax',kernel_initializer="glorot_normal",use_bias=TRUE)
summary(model)
model %>% compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')
history=model %>% fit(yyt.training,yyt.trainLabels,epochs=1000,batch_size=5,validation_split=0.2)
model=keras_model_sequential()
model %>%
layer_dense(input_shape=c(66),units=8,activation='relu',kernel_initializer="glorot_normal",use_bias=TRUE) %>%
layer_dense(units=3,activation='softmax',kernel_initializer="glorot_normal",use_bias=TRUE)
summary(model)
model %>% compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')
history=model %>% fit(yyt.training,yyt.trainLabels,epochs=1000,batch_size=5,validation_split=0.2)
plot(history)
predicted.classes=model %>% predict_classes(yyt.test)
table(yyt.testtarget,predicted.classes)
