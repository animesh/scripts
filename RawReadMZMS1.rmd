```{r setup, echo = FALSE}
.libPaths( c("L:/promec/Animesh/R/win-library/4.0", .libPaths()) )
.libPaths()
#plot
par(mfrow=c(1,2))
#data
inpD<-"L:/promec/Elite/LARS/2021/april/olej/210506 BSA SCCA/"
```

```{r getRawRead}
download.file("https://github.com/animesh/RawRead/archive/refs/heads/blazor.zip",paste0(inpD,"RawRead.zip"))
unzip(paste0(inpD,"RawRead.zip"),exdir = paste0(inpD,"RawRead"))
```

```{r data}
#generate in windows prompt using cmd
## for %i in ("L:\promec\Elite\LARS\2021\april\olej\210506 BSA SCCA\*.raw") do ("L:\promec\Elite\LARS\2021\april\olej\210506 BSA SCCA\RawRead\RawRead-blazor\RawRead.exe" "%i")
#or in bash with mono something like
## cd dir;for i in *.raw; do mono RawRead.exe $i; done
inpFL<-list.files(pattern="*MZ1R.csv$",path=inpD,full.names=F,recursive=F)
dfMZ1<-0
for(inpF in inpFL){
    print(inpF)
    data<-read.csv(paste0(inpD,inpF))
    MZ1<-data$MZ1
    dfMZ1<-union(dfMZ1,MZ1)
    colnames(data)<-paste0(colnames(data),inpF)
    hist(log2(as.numeric(data[,4])))
    data$MZ1<-MZ1
    assign(inpF,data)
}
hist(dfMZ1)
```

```{r merge}
data<-data.frame(MZ1=dfMZ1)
#data<-merge(data,`210408_EL500_SAX_urt3.raw.intensityThreshold1000.errTolDecimalPlace3.MZ1R.csv`, by="MZ1",all=T)
#plot(data$MZ1,data$MZ1210408_EL500_SAX_urt3.raw.intensityThreshold1000.errTolDecimalPlace3.MZ1R.csv)
for (obj in inpFL) {
    print(obj)
    data<-merge(data,get(obj),by="MZ1",all=T)
}
hist(data$MZ1)
write.csv(data,paste0(inpD,inpF,".combined.csv"))
```

```{r plot}
sel<-"log2sumIntensity"
sel2<-".raw.intensityThreshold1000.errTolDecimalPlace3.MZ1R.csv"
hda<-data[,grep(sel,colnames(data))]
hda<-sapply(hda,as.numeric)
colnames(hda)<-sub(sel,"",colnames(hda))
colnames(hda)<-sub(sel2,"",colnames(hda))
hist(hda)
hda[is.na(hda)]<-0
limma::vennDiagram(hda[,1:5]>0)
log2LFQimpCorr<-cor(hda,use="pairwise.complete.obs",method="spearman")
#rownames(log2LFQimpCorr)<-colnames(hda)
svgPHC<-pheatmap::pheatmap(log2LFQimpCorr,clustering_distance_rows = "euclidean",clustering_distance_cols = "euclidean",fontsize_row=8,cluster_cols=T,cluster_rows=T,fontsize_col  = 8)
```


```{r mergeData}
inpF<-"210505_SCCA_urt3b.raw.intensityThreshold1000.errTolDecimalPlace3.MZ1R.csv.combined.csv"
data<-read.csv(paste0(inpD,inpF))
dataLog2<-data[,grep("log2",colnames(data))]
dataLog2<-sapply(dataLog2,as.numeric)
rownames(dataLog2)<-data$MZ1
hist(dataLog2)
hist(dataLog2[,8])
boxplot(dataLog2)
colnames(dataLog2)
dataLog2.957.493<-dataLog2[grep("957.493",rownames(dataLog2)),]
plot(dataLog2.957.493)
dataLog2.674.254<-dataLog2[grep("674.254",rownames(dataLog2)),]
plot(dataLog2.674.254)
dataLog2.427.146<-dataLog2[grep("427.146",rownames(dataLog2)),]
plot(dataLog2.427.146)
dataLog2.276.123<-dataLog2[grep("276.123",rownames(dataLog2)),]
plot(dataLog2.276.123)
dataLog2.447.114<-dataLog2[grep("623.292",rownames(dataLog2)),]
plot(dataLog2.447.114)
dataLog2.447.114<-dataLog2[grep("460.212",rownames(dataLog2)),]
plot(dataLog2.447.114)
dataLog2.615.191<-dataLog2[grep("615.191",rownames(dataLog2)),]
plot(dataLog2.615.191)
dataLog2.447.114<-dataLog2[grep("447.114",rownames(dataLog2)),]
plot(dataLog2.447.114)
dataLog2.447.114<-dataLog2[grep("342.111",rownames(dataLog2)),]
plot(dataLog2.447.114)
dataLog2.447.114<-dataLog2[grep("342.112",rownames(dataLog2)),]
plot(dataLog2.447.114)
dataLog2.447.114
```

```{r norm}
boxplot(hda)
#BiocManager::install("vsn")
#dataLog2VSN<-vsn::justvsn(dataLog2)
#boxplot(dataLog2VSN)
#dataLog2.447.114<-dataLog2VSN[grep("615.191",rownames(dataLog2VSN)),]
#plot(dataLog2.447.114)
#dataLog2.447.114<-dataLog2VSN[grep("447.114",rownames(dataLog2VSN)),]
#plot(dataLog2.447.114)
#BiocManager::install("DAPAR")
#dataLog2QC <- wrapper.normalizeD(obj = dataLog2, method = "QuantileCentering", conds=c(1:8), type = "within conditions")
#boxplot(dataLog2QC)
dataLog2NormLOESS<-limma::normalizeCyclicLoess(dataLog2, weights = NULL, span=0.7, iterations = 3, method = "fast")
boxplot(dataLog2NormLOESS)
dataLog2.615.191<-dataLog2NormLOESS[grep("615.191",rownames(dataLog2NormLOESS)),]
plot(dataLog2.615.191)
dataLog2.447.114<-dataLog2NormLOESS[grep("447.114",rownames(dataLog2NormLOESS)),]
plot(dataLog2.447.114)
```


```{r anion}
dataAnion<-data[-grep("Scan",data$Scan1),c(2,4)]
dataAnion$intensity<-as.numeric(dataAnion$intensity)
dataAnion$MZ<-strtrim(dataAnion$MZ,7)
summary(dataAnion)
```

```{r anionAgg}
#sapply(dataAnion, as.numeric)
dataAnionAgg7lMax<-tapply(dataAnion$intensity,dataAnion$MZ,max)
summary(dataAnionAgg7lMax)
dataAnionAgg7lMaxF<-as.data.frame(dataAnionAgg7lMax)
hist(log2(dataAnionAgg7lMaxF$dataAnionAgg7lMax))
dataAnionAgg7lMaxF$MZ<-row.names(dataAnionAgg7lMaxF)
dataAnionAgg7lMaxF<-dataAnionAgg7lMaxF[dataAnionAgg7lMaxF$dataAnionAgg7lMax>0,]
row.names(dataAnionAgg7lMaxF)
write.csv(dataAnionAgg7lMaxF,paste(getwd(),inpF,"dataagg7lMaxF.csv",sep="_"),row.names = F)
```

```{r}
#install.packages("XML")
#library("XML")
data <- XML::xmlToDataFrame("F:/promec/Animesh/hmdb_metabolites/hmdb_metabolites.xml")
data$MZ<-strtrim(data$monisotopic_molecular_weight,7)
data$MZHp<-(as.numeric(data$monisotopic_molecular_weight)+1.007825035)/1.007825035
data$MZHp7<-strtrim(data$MZHp,7)
data$MZHp6<-strtrim(data$MZHp,6)
write.csv(data,"F:/promec/Animesh/hmdb_metabolites/hmdb_metabolites.xml.csv")
#print(data)
```

```{r}
data <- read.csv("L:/promec/Qexactive/LARS/2020/september/hmdb_metabolites.xml.csv")
data$MZ7<-strtrim(data$monisotopic_molecular_weight,7)
data$MZHp<-(as.numeric(data$monisotopic_molecular_weight)+1.007825035)/1.007825035
data$MZHp7<-strtrim(data$MZHp,7)
summary(data)
#print(data)
```

```{r cation}
MZ1<-read.csv("L:/promec/Qexactive/LARS/2020/september/mz1coll.csv")
sum(as.numeric(MZ1[,2])-as.numeric(MZ1[,3]))
rowMinMZ1<-apply(MZ1, 1, FUN=min)
rowMaxMZ1<-apply(MZ1, 1, FUN=max)
MZ1min10e7<-cbind(MZ1,rowMinMZ1)
MZ1max10e7<-cbind(MZ1min10e7,rowMaxMZ1)
MZ1max10e7<-MZ1max10e7[MZ1max10e7$rowMaxMZ1>10e6,]
hist(log2(as.numeric(MZ1max10e7$rowMaxMZ1)))
MZ1max10e7$MZ7<-strtrim(MZ1max10e7$MZ,7)
summary(MZ1max10e7)
write.csv(MZ1max10e7,"L:/promec/Qexactive/LARS/2020/september/mz1coll.10e7.csv")
```

```{r cation}
first500<-read.csv("L:/promec/Qexactive/LARS/2020/september/search (11).csv")
summary(first500)
```

```{r cation}
second500<-read.csv("L:/promec/Qexactive/LARS/2020/september/search (12).csv")
summary(second500)
```

```{r writeAnionChk}
webQhmdb<-rbind(first500,second500)
summary(webQhmdb)
MZ1max10e7webQhmdb<-merge(MZ1max10e7,by.x="MZ7",webQhmdb,by.y="query_mass", all.x = TRUE)
write.csv(MZ1max10e7webQhmdb,"L:/promec/Qexactive/LARS/2020/september/MZ1max10e7webQhmdb.csv")
```

```{r writeAnionChk}
MZ1max10e7combo<-merge(MZ1max10e7,by.x="MZ7",data,by.y="MZ7", all.x = TRUE)
MZ1max10e7combo2<-merge(MZ1max10e7combo,by.x="MZ7",data,by.y="MZHp7", all.x = TRUE)
write.csv(MZ1max10e7combo2,"L:/promec/Qexactive/LARS/2020/september/MZ7HP7.csv")
```

```{r writeAnionChk}
MZ1max10e7$MZ6<-strtrim(MZ1max10e7$MZ,6)
MZ1max10e7combo<-merge(MZ1max10e7,by.x="MZ6",data,by.y="MZHp6",all = F)
write.csv(MZ1max10e7combo,paste(getwd(),inpF,"chk.csv",sep="_"))
```

```{r writeAnionChk}
MZ1max10e7$MZ6<-strtrim(MZ1max10e7$MZ,6)
MZ1max10e7combo<-merge(MZ1max10e7,by.x="MZ6",data,by.y="MZHp6",all = F)
write.csv(MZ1max10e7combo,paste(getwd(),inpF,"chk.csv",sep="_"))
```


```{r chk}
chk<-as.data.frame(c(376.259,472.157,393.285,194.102))
colnames(chk)<-"Test"
```

```{r writeAnionChk}
anion<-merge(chk,by.x="Test",dataAnionAgg7lMaxF,by.y="MZ",all = F)
write.csv(anion,paste(getwd(),inpF,"chk.csv",sep="_"))
```

```{r anionHMDB}
hmdA<-read.csv(paste(getwd(),"search (5).csv",sep="/"))
hist(hmdA[,1])
hmdA[,1]<-sprintf(hmdA[,1], fmt = '%#.3f')
hist(hmdA[,10])
```

```{r writeAnion}
anion<-merge(dataAnionAgg7lMaxF,by.x="MZ",hmdA,by.y="query_mass",all = T)
write.csv(anion,paste(getwd(),"200921_fraksjonANIONfrak4_URT1_20200923030614.raw.profile.intensity0.charge0.MS.dataagg7lMaxF10e6.HMDB.csv",sep="/"))
```

```{r cation}
data<-read.csv(paste(getwd(),"200921_fraksjonFTcation_URT1_20200923005518.raw.profile.intensity0.charge0.MS.txt",sep="/"),sep='\t')
hist(as.numeric(data[,2]))
hist(log2(as.numeric(data[,4])))
dataCation<-data[-grep("Scan",data$Scan1),c(2,4)]
dataCation$intensity<-as.numeric(dataCation$intensity)
dataCation$MZ<-strtrim(dataCation$MZ,7)
summary(dataCation)
```

```{r cationAgg}
#sapply(dataAnion, as.numeric)
dataCationAgg7lMax<-tapply(dataCation$intensity,dataCation$MZ,max)
summary(dataCationAgg7lMax)
dataCationAgg7lMaxF<-as.data.frame(dataCationAgg7lMax)
hist(log2(dataCationAgg7lMaxF$dataCationAgg7lMax))
dataCationAgg7lMaxF$MZ<-row.names(dataCationAgg7lMaxF)
dataCationAgg7lMaxF<-dataCationAgg7lMaxF[dataCationAgg7lMaxF$dataCationAgg7lMax>10e6,]
row.names(dataCationAgg7lMaxF)
write.csv(dataCationAgg7lMaxF,paste(getwd(),"200921_fraksjonFTcation_URT1_20200923005518.raw.profile.intensity0.charge0.MS.dataagg7lMaxF10e6.csv",sep="/"),row.names = F)
```

```{r cationHMDB}
hmdC<-read.csv(paste(getwd(),"search (4).csv",sep="/"))
hist(hmdC[,1])
hmdC[,1]<-sprintf(hmdC[,1], fmt = '%#.3f')
hist(hmdC[,10])
```

```{r}
cation<-merge(dataCationAgg7lMaxF,by.x="MZ",hmdC,by.y="query_mass",all = T)
write.csv(cation,paste(getwd(),"200921_fraksjonFTcation_URT1_20200923005518.raw.profile.intensity0.charge0.MS.dataagg7lMaxF10e6.HMDB.csv",sep="/"))
```

```{r writeCation}
ion<-merge(dataCationAgg7lMaxF,by.x="MZ",dataAnionAgg7lMaxF,by.y="MZ",all = T)
write.csv(ion,paste(getwd(),"200921_fraksjonION_URT1.raw.profile.intensity0.charge0.MS.dataagg7lMaxF10e6.csv",sep="/"))
```

```{r map}
hmdI<-read.csv(paste(getwd(),"search (7).csv",sep="/"))
hist(hmdI[,1])
hmdI[,1]<-sprintf(hmdI[,1], fmt = '%#.3f')
hist(hmdI[,10])
hmdIon<-merge(ion,by.x="MZ",hmdI,by.y="query_mass",all = T)
write.csv(hmdIon,paste(getwd(),"200921_hmdIon_URT1.raw.profile.intensity0.charge0.MS.dataagg7lMaxF10e6.csv",sep="/"))
```

```{r anionAggMedian}
#sapply(dataAnion, as.numeric)
dataAnionAgg7lMedian<-tapply(dataAnion$intensity,dataAnion$MZ,median)
summary(dataAnionAgg7lMedian)
dataAnionAgg7lMedianF<-as.data.frame(dataAnionAgg7lMedian)
hist(log2(dataAnionAgg7lMedianF$dataAnionAgg7lMedian))
dataAnionAgg7lMedianF$MZ<-row.names(dataAnionAgg7lMedianF)
dataAnionAgg7lMedianF<-dataAnionAgg7lMedianF[dataAnionAgg7lMedianF$dataAnionAgg7lMedian>10e5,]
row.names(dataAnionAgg7lMedianF)
write.csv(dataAnionAgg7lMedianF,paste(getwd(),"200921_fraksjonANIONfrak4_URT1_20200923030614.raw.profile.intensity0.charge0.MS.dataagg7lMedianF10e6.csv",sep="/"),row.names = F)
```

```{r checkPkg}
#install.packages("BiocManager")
metanr_packages <- function(){
metr_pkgs <- c("impute", "pcaMethods", "globaltest", "GlobalAncova", "Rgraphviz", "preprocessCore", "genefilter", "SSPA", "sva", "limma", "KEGGgraph", "siggenes","BiocParallel", "MSnbase", "multtest","RBGL","edgeR","fgsea","devtools","crmn")
list_installed <- installed.packages()
new_pkgs <- subset(metr_pkgs, !(metr_pkgs %in% list_installed[, "Package"]))
if(length(new_pkgs)!=0){if (!requireNamespace("BiocManager", quietly = TRUE))
        install.packages("BiocManager")
        BiocManager::install(new_pkgs)
        print(c(new_pkgs, " packages added..."))
    }

if((length(new_pkgs)<1)){
        print("No new packages added...")
    }
}
metanr_packages()
```

```{r installPkg} 
#install.packages("pacman")
#pacman::p_load(c("impute", "pcaMethods", "globaltest", "GlobalAncova", "Rgraphviz", "preprocessCore", "genefilter", "SSPA", "sva", "limma", "KEGGgraph", "siggenes","BiocParallel", "MSnbase", "multtest","RBGL","edgeR","fgsea"))
#rm -rf /home/animeshs/R/x86_64-pc-linux-gnu-library/3.6/*
#sudo apt-get install r-cran-ncdf4
BiocManager::install("mzR")
BiocManager::install("ctc")
install.packages("gdata")
install.packages("glasso")
install.packages("huge")
install.packages("ppcor")
install.packages("plotly")
devtools::install_github("xia-lab/MetaboAnalystR", build = TRUE, build_vignettes = FALSE)
library(MetaboAnalystR)
```

```{r}
tmp.vec <- c("Acetoacetic acid", "Beta-Alanine", "Creatine", "Dimethylglycine", "Fumaric acid")
mSet<-InitDataObjects("conc", "msetora", FALSE)
mSet<-Setup.MapData(mSet, tmp.vec)
mSet<-CrossReferencing(mSet, "name")
mSet<-CreateMappingResultTable(mSet)
mSet<-SetMetabolomeFilter(mSet, F)
mSet<-SetCurrentMsetLib(mSet, "smpdb_pathway", 2)
mSet<-CalculateHyperScore(mSet)
mSet<-PlotORA(mSet, "ora_0_", "bar", "png", 72, width=NA)
```

```{r}
# https://drive.google.com/file/d/1CXluzyYqNoPqu1DI3HwvDAmRVGMe825m/view Create vector consisting of compounds for enrichment analysis
tmp.vec <- c("Acetoacetic acid", "Beta-Alanine", "Creatine", "Dimethylglycine", "Fumaric acid", "Glycine", "Homocysteine", "L-Cysteine", "L-Isolucine", "L-Phenylalanine", "L-Serine", "L-Threonine", "L-Tyrosine", "L-Valine", "Phenylpyruvic acid", "Propionic acid", "Pyruvic acid", "Sarcosine")
# Create mSetObj for storing objects created during your analysis
mSet<-InitDataObjects("conc", "pathora", FALSE)
# Set up mSetObj with the list of compounds
mSet<-Setup.MapData(mSet, tmp.vec);
# Cross reference list of compounds against libraries (hmdb, pubchem, chebi, kegg, metlin)
mSet<-CrossReferencing(mSet, "name");
# Creates a mapping result table; shows HMDB, KEGG, PubChem, etc. IDs
# Saved as "name_map.csv" or can be found in mSet$dataSet$map.table
# Compounds with no hits will contain NAs across the columns
mSet<-CreateMappingResultTable(mSet);
# From the mapping result table, L-Isolucine has no matches
# Now, perform potential matching with our database against this compound
mSet<-PerformDetailMatch(mSet, "L-Isolucine");
# Get list of candidates for matching
# Results are found in mSet$name.map$hits.candidate.list
mSet<-GetCandidateList(mSet);
# Replace L-Isolucine with selected compound (L-Isoleucine)
mSet<-SetCandidate(mSet, "L-Isolucine", "L-Isoleucine");
# Select the pathway library, ranging from mammals to prokaryotes
# Note the third parameter, where users need to input the KEGG pathway version.
# Use "current" for the latest KEGG pathway library or "v2018" for the KEGG pathway library version prior to November 2019.
mSet<-SetKEGG.PathLib(mSet, "hsa", "current")
# Set the metabolite filter
# Default set to false
mSet<-SetMetabolomeFilter(mSet, F);
# Calculate the over representation analysis score, here we selected to use the hypergeometric test (alternative is Fisher's exact test)
# A results table "pathway_results.csv" will be created and found within your working directory
mSet<-CalculateOraScore(mSet, "rbc", "hyperg")
# Plot of the Pathway Analysis Overview
mSet<-PlotPathSummary(mSet,"path_view_0_","png",72,width=NA)
# Plot a specific metabolic pathway, in this case "Glycine, serine and threonine metabolism"
mSet<-PlotKEGGPath(mSet, "Glycine, serine and threonine metabolism",528, 480, "png", NULL)
```

```{r}
#https://drive.google.com/file/d/1HVoXNX98CZLcpr7MkpVZP5DueXcnZeIj/view
#download.file("https://www.metaboanalyst.ca/MetaboAnalyst/resources/data/integ_genes.txt", "integ_genes.txt", "curl")
#download.file("https://www.metaboanalyst.ca/MetaboAnalyst/resources/data/integ_cmpds.txt", "integ_cmpds.txt", "curl")
# Initiate MetaboAnalyst
mSet<-InitDataObjects("conc", "pathinteg", FALSE)
# Set organism library
mSet<-SetOrganism(mSet, "hsa")
# Set the name of your file containing your gene list
geneListFile<-"integ_genes.txt"
# Read in your gene list file
geneList<-readChar(geneListFile, file.info(geneListFile)$size)
# Perform gene mapping of your file
mSet<-PerformIntegGeneMapping(mSet, geneList, "hsa", "symbol");
# Set the name of your file containing your compound list
cmpdListFile<-"integ_cmpds.txt"
# Read in your compound list file
cmpdList<-readChar(cmpdListFile, file.info(cmpdListFile)$size)
# Perform compound mapping of your file
mSet<-PerformIntegCmpdMapping(mSet, cmpdList, "hsa", "kegg");
# Create a mapping result table
mSet<-CreateMappingResultTable(mSet)
# Prepare data for joint pathway analysis
mSet<-PrepareIntegData(mSet)
mSet
```

```{r}
mSet1<-PerformIntegPathwayAnalysis(mSet, "dc", "hyper", "current", "integ", "query");
# View the output of the pathway analysis
mSet1$dataSet$path.mat
mSet2<-PerformIntegPathwayAnalysis(mSet, "bc", "fisher", "current", "all", "query")
PlotPathSummary(mSet, "path_view_0_", "png", 72, width=NA)
PlotPathSummary(mSet1, "path_view_0_", "png", 72, width=NA)
PlotPathSummary(mSet2, "path_view_0_", "png", 72, width=NA)
```

```{r}
##https://drive.google.com/file/d/1fZ364APP8pqemFg0oD0kIhAzH9Zm9p-0/view
## METABOLITE-DISEASE INTERACTION NETWORK
##
# Create objects for storing processed data from the network explorer module
mSet<-InitDataObjects("conc", "network", FALSE)
# Set organism to human, at the moment only human data can be accomodated
mSet<-SetOrganism(mSet, "hsa")
# Set geneListFile as a file containing your gene list
geneListFile<-"integ_genes.txt"
# Read in the geneListFile
# This will import a plain text file as single character string
geneList<-readChar(geneListFile, file.info(geneListFile)$size)
# Perform gene ID mapping
mSet<-PerformIntegGeneMapping(mSet, geneList, "hsa", "symbol");
# Set cmpdListFile as a file containing your metablolite list
cmpdListFile<-"integ_cmpds.txt"
# Read in the cmpdListFile
# This will import a plain text file as single character string
cmpdList<-readChar(cmpdListFile, file.info(cmpdListFile)$size)
# Perform compound ID mapping
mSet<-PerformIntegCmpdMapping(mSet, cmpdList, "hsa", "kegg");
# Create the mapping results table for compounds
mSet<-CreateMappingResultTable(mSet)
# Create the mapping results table for genes
mSet<-GetNetworkGeneMappingResultTable(mSet)
# Prepare the data for network analysis, saves a .json file that can be uploaded
# to external sites/packages to view the network
mSet<-PrepareNetworkData(mSet);
# Map user's data to internal interaction network
mSet<-SearchNetDB(mSet, "pheno", "global", FALSE, 0.5)
# Create graph and subnetworks
mSet<-CreateGraph(mSet)
```

```{r}
mSet<-InitDataObjects("mass_all", "mummichog", FALSE)
SetPeakFormat("rmp")
mSet<-UpdateInstrumentParameters(mSet, 20.0, "positive", "yes", 0.02);
mSet<-Read.PeakListData(mSet, "Replacing_with_your_file_path");
mSet<-SanityCheckMummichogData(mSet)
mSet<-SetPeakEnrichMethod(mSet, "integ", "v2")
mSet<-SetMummichogPval(mSet, 1.0E-5)
mSet<-PerformPSEA(mSet, "hsa_mfn", "current", 100)
mSet<-PlotIntegPaths(mSet, "integ_peaks_0_", "png", 72, width=NA)
```

