Scratch for R
**check**
========================================================
```{r setup}
library(r2d3)
bars <- c(10, 20, 30)
```

```{d3 data=bars, options=list(color = 'orange')}
svg.selectAll('rect')
  .data(data)
  .enter()
    .append('rect')
      .attr('width', function(d) { return d * 10; })
      .attr('height', '20px')
      .attr('y', function(d, i) { return i * 22; })
      .attr('fill', options.color);
```

```{r data, echo = FALSE}
scriptD <- 'C:\\Users\\animeshs\\Desktop\\scripts\\'
inpD <-'L:\\promec\\Elite\\LARS\\2014\\desember\\christiano\\'
data <- read.delim(paste0(inpD,"proteinGroups.txt"),row.names=1,sep="\t",header = T)
summary(data)
decoyPrefix="REV"
contaminantPrefix="CON"
dataC="LFQ.intensity."
```

```{r ROTS, echo = FALSE}
#install.packages("BiocManager")
#BiocManager::install("ROTS", version = "3.8")
dataNormImpCom[is.na(dataNormImpCom)]=5
summary(dataNormImpCom)
library(ROTS)
data(upsSpikeIn)
input = upsSpikeIn
groups = c(rep(0,3), rep(1,3))
groups
results = ROTS(data = input, groups = groups , B = 100 , K = 500 , seed = 1234)
names(results) 
summary(results, fdr = 0.05)
plot(results, fdr = 0.2, type = "volcano")
#plot(results, fdr = 0.05, type = "heatmap")
```

```{r reticulate, echo = FALSE}
#https://rviews.rstudio.com/2019/03/18/the-reticulate-package-solves-the-hardest-problem-in-data-science-people/
install.packages('mlbench') #provides the data set
library(mlbench) #provides the data set
data("BreastCancer")
#convert to numeric for models and remove na values for this example
install.packages('xgboost')
library(xgboost)

model_set <- sapply(BreastCancer[complete.cases(BreastCancer),-1], as.numeric) 

#format target variable as 0, 1 instead of 1,2
model_set[,10]<-model_set[,10]-1 
  
#Split into test and train sets
indices <- sample(1:nrow(model_set), size = 0.7 * nrow(model_set))

#Target variables
target<-unlist(model_set[indices,10])
test_target<-unlist(model_set[-indices,10])

#create unscaled data set for boosted tree models
unscale_train<-as.matrix(model_set[indices,-10])
unscale_test<-as.matrix(model_set[-indices,-10 ])

#create normalized data set for neural network
mean <- apply(model_set[indices,-10], 2, mean)
std <- apply(model_set[indices,-10], 2, sd)

train <- scale(model_set[indices,-10], center = mean, scale = std)
test <- scale(model_set[-indices,-10], center = mean, scale = std)

boost_model<-xgboost(data = unscale_train,label=target,booster="gbtree", nfold = 2,nrounds = 25, verbose = FALSE, objective = "binary:logistic", eval_metric = "auc", nthread = 4)

install.packages('dplyr')
library(dplyr)

install.packages('keras')
library(keras)
y_target<-to_categorical(target,2)

tf_nn <- keras_model_sequential() %>%
  layer_dense(units = 12,
              activation = 'relu',
              input_shape = dim(train)[[2]]) %>% 
  layer_dropout(rate = 0.4) %>% 
  layer_dense(units = 12,
              activation = 'relu')%>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 2,
              activation = 'softmax')


tf_nn %>% compile(
  optimizer = optimizer_rmsprop(),
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)

history<-tf_nn %>% fit(
  x=train,
  y=y_target,
  epochs = 7,
  batch_size = 12
)

```

```{r stan, echo = FALSE}
library('rstan')
stan(paste0(scriptD,'school8.stan'))
```


```{r tmp, echo = FALSE}
frac $\frac{1}{n}$ 
memory.size(TRUE)
memory.limit()
rm(list=ls())
```

```{r python, echo = FALSE}
#install.packages('reticulate')
#install.packages("reticulate")
#devtools::install_github("rstudio/reticulate")
#library('reticulate')
#Sys.which("python")
devtools::install_github("rstudio/reticulate")
```

```{r d3, echo = FALSE}
#install.packages('devtools')
#devtools::install_github("rstudio/r2d3")
library(r2d3)
r2d3(data=c(0.3, 0.6, 0.8, 0.95, 0.40, 0.20), script = "barchart.js")
a=c(c(1,2) c(2,1))
dim(a)<-c(2,2)
(a)*t(a)
cov(a)
```



```{r shiny, echo = FALSE}
#https://rmarkdown.rstudio.com/authoring_shiny.html
#install.packages('shiny')
library(shiny)
dN_shiny <- dataNorm
#ctrl-shift-K
#rmarkdown::run
#shiny::renderUI
```

```{r slider, echo=FALSE}

inputPanel(
  sliderInput("bins", "#bins:", min = 1, max = 100, value = 30),
  textInput("dens", "Density:", "auto",value = 0.6), 
  selectInput("expression", label = "Sample:",choices = colnames(dN_shiny), selected = colnames(dN_shiny)[1]))
renderText({paste("Inputs:", input$bins,input$dens,input$expression)})
```

```{r plot, echo = FALSE}
renderPlot({
  hist(dN_shiny[,as.numeric(which(colnames(dN_shiny) == input$expression))],breaks = as.numeric(input$bins),probability = TRUE,col="orange")
  lines(density(dN_shiny[,as.numeric(which(colnames(dN_shiny) == input$expression))], adjust = as.numeric(input$dens)),col="blue")
  })
  
```

```{r UWOT, echo = FALSE}
#devtools::load_all()
#install.packages('devtools')
#library('devtools')
#install_github("jlmelville/uwot")
library()
iris_umap <- umap(iris, n_neighbors = 50, learning_rate = 0.5, init = "random")

# Load mnist from somewhere, e.g.
# devtools::install_github("jlmelville/snedata")
# mnist <- snedata::download_mnist()
mnist_umap <- umap(mnist, n_neighbors = 15, min_dist = 0.001, verbose = TRUE)

# Use a specific number of threads
mnist_umap <- umap(mnist, n_neighbors = 15, min_dist = 0.001, verbose = TRUE, n_threads = 8)

# Use a different metric
mnist_umap_cosine <- umap(mnist ,n_neighbors = 15, metric = "cosine", min_dist = 0.001, verbose = TRUE, n_threads = 8)

# Supervised dimension reduction
mnist_umap_s <- umap(mnist, n_neighbors = 15, min_dist = 0.001, verbose = TRUE, n_threads = 8, 
                     y = mnist$Label, target_weight = 0.5)
                    
# Add new points to an existing embedding
mnist_train <- head(mnist, 60000)
mnist_test <- tail(mnist, 10000)

# You must set ret_model = TRUE to return extra data we need
# coordinates are in mnist_train_umap$embedding
mnist_train_umap <- umap(mnist_train, verbose = TRUE, ret_model = TRUE)
mnist_test_umap <- umap_transform(mnist_test, mnist_train_umap, verbose = TRUE)

# Save the nearest neighbor data
mnist_nn <- umap(mnist, ret_nn = TRUE)
# coordinates are now in mnist_nn$embedding

# Re-use the nearest neighor data and save a lot of time
mnist_nn_spca <- umap(mnist, nn_method = mnist_nn$nn, init = spca)

# No problem to have ret_nn = TRUE and ret_model = TRUE at the same time

# Calculate Petal and Sepal neighbors separately (uses intersection of the resulting sets):
iris_umap <- umap(iris, metric = list("euclidean" = c("Sepal.Length", "Sepal.Width"),
                                      "euclidean" = c("Petal.Length", "Petal.Width")))
# Can also use individual factor columns
iris_umap <- umap(iris, metric = list("euclidean" = c("Sepal.Length", "Sepal.Width"),
                                      "euclidean" = c("Petal.Length", "Petal.Width"),
                                      "categorical" = "Species"))
                                      
# MNIST with PCA reduction to 50 dimensions can speed up calculation without
# affecting results much
mnist_umap <- umap(mnist, pca = 50)

```


```{r clusterProfiler, echo = FALSE}
#BiocManager::install("STRINGdb")
library(STRINGdb)
string_db <- STRINGdb$new( version="11", species=9606,score_threshold=0, input_directory="" )
UniprotStrings<-as.data.frame(Uniprot)
example1_mapped <- string_db$map( UniprotStrings, "Uniprot", removeUnmappedRows = TRUE )
hits<-example1_mapped$STRING_id
enrichmentGO <- string_db$get_enrichment( hits, category = "Process", methodMT = "fdr", iea = TRUE )
enrichmentKEGG <- string_db$get_enrichment( hits, category = "KEGG", methodMT = "fdr", iea = TRUE )
head(enrichmentGO, n=7)
head(enrichmentKEGG, n=7)
```



```{r clusterProfiler, echo = FALSE}
install.packages('BiocManager')
BiocManager::install('goseq')
library(goseq)
supportedOrganisms() 
#https://bioconductor.org/packages/release/bioc/vignettes/clusterProfiler/inst/doc/clusterProfiler.html
#source("https://bioconductor.org/biocLite.R")
## biocLite("BiocUpgrade") ## you may need this
#biocLite("clusterProfiler")
#biocLite("org.Hs.eg.db")
library("org.Hs.eg.db")
#install.packages("colorspace")
#devtools::install_github('cran/colorspace')
library("clusterProfiler")
Uniprot=data[data$`MCCAR Biol Rep 25 WSRT``NB4 Biol Rep 22 WSRT`<0.5,1]
dataSub=subset(data,`NB4 Biol Rep 22 WSRT`<0.3 & `MCCAR Biol Rep 25 WSRT`<0.3)
Uniprot<-sapply(strsplit(dataSub$`T: Majority protein IDs`,";"), `[`, 1)
enrichGO(gene=Uniprot,OrgDb=org.Hs.eg.db,keyType= 'UNIPROT',ont= "CC",pAdjustMethod = "BH",pvalueCutoff  = 0.01,qvalueCutoff  = 0.05)
UniprotEG<-bitr(Uniprot, fromType="UNIPROT", toType="ENTREZID", OrgDb="org.Hs.eg.db")
UniprotKEGG<-bitr(Uniprot, fromType="UNIPROT", toType="KEGG", OrgDb="org.Hs.eg.db")
UniprotKEGG<-bitr_kegg(Uniprot, fromType='uniprot', toType='kegg', organism='hsa')
kk <- enrichKEGG(gene=UniprotEG$ENTREZID)
kk@result[["Description"]]
browseKEGG(kk,kk@result[["ID"]][1])
```


```{r installs}
install.packages(c("matrixStats", "Hmisc", "splines", "foreach", "doParallel", "fastcluster", "dynamicTreeCut", "survival"))
source("http://bioconductor.org/biocLite.R") 
biocLite(c("GO.db", "preprocessCore", "impute"))
orgCodes = c("Hs", "Mm", "Rn", "Pf", "Sc", "Dm", "Bt", "Ce", "Cf", "Dr", "Gg"); 
orgExtensions = c(rep(".eg", 4), ".sgd", rep(".eg", 6)); 
packageNames = paste("org.", orgCodes, orgExtensions, ".db", sep=""); 

biocLite(c("GO.db", "KEGG.db", "topGO", packageNames, "hgu133a.db", "hgu95av2.db", "annotate", "hgu133plus2.db", "SNPlocs.Hsapiens.dbSNP.20100427", "minet", "OrderedList"))
install.packages("BiocManager") 
BiocManager::install("WGCNA") 
library(WGCNA);
allowWGCNAThreads()
```


```{r data}
femData <- read.csv("https://raw.githubusercontent.com/iamciera/10wgcna/master/examples/LiverFemale3600.csv")
names(femData)

#This is just melting the data without the first 8 columns or something
datExpr0 <- as.data.frame(t(femData[, -c(1:8)]))
names(datExpr0) = femData$substanceBXH
rownames(datExpr0) = names(femData)[-c(1:8)]

head(datExpr0[,1:8])

datExpr0 = as.data.frame(t(femData[, -c(1:8)]));
gsg = goodSamplesGenes(datExpr0, verbose = 3)
gsg$allOK
install.packages('flashClust')
library(flashClust)
sampleTree = flashClust(dist(datExpr0), method = "average");
plot(sampleTree, main = "Sample clustering to detect outliers", sub="", xlab="", cex.lab = 1.5,
     cex.axis = 1.5, cex.main = 2)

net = blockwiseModules(datExpr0, power = 6,
                       TOMType = "unsigned", minModuleSize = 30,
                       reassignThreshold = 0, mergeCutHeight = 0.25,
                       numericLabels = TRUE, pamRespectsDendro = FALSE,
                       saveTOMs = TRUE,
                       saveTOMFileBase = "femaleMouseTOM", 
                       verbose = 3)
#https://jolars.github.io/eulerr/articles/venn-diagrams.html
install.packages('eulerr')
library(eulerr)
s4 <- list(a = c(1, 2, 3),
           b = c(1, 2),
           c = c(1, 4),
           e = c(5))
plot(venn(s4))
plot(euler(s4, shape = "ellipse"), quantities = TRUE)

#https://github.com/jolars/eulerr.co/blob/master/server.R

library(ggplot2)

#heatmap(data$Difference)
p <- ggplot(data,aes(Difference,X.Log.P.value.))
p<-p + geom_tile(aes(fill=X.Log.P.value.)) + scale_fill_gradient(low="white", high="darkblue") + xlab("") + ylab("")
f=paste(file,proc.time()[3],".jpg")
ggsave(filename=f, plot=p)
print(p)
data <- read.delim("Y:/felles/Voin/===Methodology paper===/Supplementary table Ttest BothSided Sample.txt",row.names=22,sep="\t",header = T)
data <- read.delim("Supplementary table Ttest BothSided",row.names=22,sep="\t",header = T)
summary(data)
```

```{r xplot}

library('ggplot2')
data[1,]
Significance=data$X.Log.P.value.>-log10(0.05)&abs(data$Difference)>log2(1.5)
sum(Significance)
dsub <- subset(data, data$X.Log.P.value.==max(data$X.Log.P.value.)|data$Difference==max(abs(data$Difference)))
dsub$Gene.names
plot(data$Difference,data$X.Log.P.value.)
qplot(Difference,X.Log.P.value.,data=data,color=X.Log.P.value.>-log10(0.05)&abs(Difference)>log2(1.5))
g = ggplot(data,aes(Difference,X.Log.P.value.))
gps<-g + geom_point(aes(color=Significance)) + theme_bw(base_size=10) + geom_text(data=dsub,aes(label=Gene.names),hjust=0, vjust=0) + xlab("Log2 Fold Change")  + ylab("-Log10 P-value") + ggtitle("Differentially expressed proteins") + scale_size_area()
p=paste(file,proc.time()[3],".jpg")
ggsave(filename=p, plot=gps)
```



```{r, echo=FALSE}
plot(log2(data$A549.Cis.1/100),log2(data$A549.Cis.2/100),col="#FF00FF",cex=0.5,pch=16,lty=1)
```

```{r sign-test}

set.seed(2016)
bio <- 3
prot <- nrow(data)
wilcox.test(data)
dataa549cis = t(data[,grepl( "^A549.Cis",names(data))])
dataa549cis[is.nan(dataa549cis)] <- NA
dataa549cis = t(c(-1,2,3,4,50))
results <- apply(dataa549cis, 1, function(dataa549cis) {
  wilcox.test(dataa549cis)$p.value})
results


results <- apply(dat, 1, function(dat) {
  wilcox.test(x = dat[1:x])$p.value})


results <- apply(data, 1, function(data) {
  wilcox.test(x = data[,grepl( "^A549.Cis",names(data))])$p.value})

results <- apply(data, 1, function(data) {
  wilcox.test(x = log2(data[,grepl( "^A549.Cis",names(data))])$p.value}))
results <- apply(data, 1, function(data) {
  wilcox.test(x=log2(data$A549.Cis.1/100))$p.value})
cbind(data, pvals = results)

hist(p.adjust(results,method="BH"))
hist(p.adjust(results,method="BH"))
hist(p.adjust(results,method="holm"))
?p.adjust
hist(results)
min(results)
data=read.delim("C:/Users//animeshs/Google Drive/wilcox_sgn_rnk_wiki.txt",row.names=1)
wilcox.test(data$x2,data$x1,paired = TRUE, alternative = "less")
wilcox.test(data$x2,data$x1,paired = TRUE, alternative = "greater")
wilcox.test(data$x2,data$x1,paired = TRUE)
wilcox.test(c(1,1,1,1,1))
0.5^4
wilcox.test((data$x2-data$x1))$pvalue
binom.test(3,3)
sum(data$sgn>0, na.rm=TRUE)
binom.test(1,3)
t.test(c(data$x1,data$x2),c(data$abs,data$abs))
t.test(extra ~ group, data = sleep)
wilcox.test(extra ~ group, data = sleep)


x <- 10; y <- 10; g <- 1000
mean(c(1,2,3))
set.seed(1969)
dat <- matrix(rnorm((x + y) * g), ncol = x + y)

results <- apply(dat, 1, function(dat) {
  wilcox.test(x = dat[1:x])$p.value})

cbind(dat, pvals = results)
hist(results,col="orange")
hist(p.adjust(results,method="BH"))

#write.csv2("Y:/felles/Voin/===Methodology paper===/Supplementary table WCSR_test.txt",results)
install.packages("rlm")
library(rlm)
?rlm
qqnorm(c(1,2,10,100))
?qqplot


install.packages("outliers")
library(outliers)
grubbs.test(c(10,20, 200))



```





```{r MSstat}
source("http://bioconductor.org/biocLite.R")
biocLite("MSstats")
library("MSstats")


```

```{r interactive}
#install.packages("shiny")
library(shiny)
runExample("01_hello")
```

```{r google}
install.packages("RGoogleAnalytics")
library("RGoogleAnalytics")
```

```{r googleVis}
#install.packages("googleVis")
#suppressPackageStartupMessages(library(googleVis))
#http://rpubs.com/gallery/googleVis
T <- gvisTable(Exports, options = list(width = 200, height = 280))
G <- gvisGeoChart(Exports, locationvar = "Country", colorvar = "Profit", 
    options = list(width = 360, height = 280, dataMode = "regions"))
TG <- gvisMerge(T, G, horizontal = TRUE, tableOptions = "bgcolor=\"#CCCCCC\" cellspacing=10")

print(TG, "chart")
```

**check**
```{r Hurricane Andrew (1992) storm track with Google Maps}
AndrewMap <- gvisMap(Andrew, "LatLong", "Tip", options = list(showTip = TRUE, 
    showLine = TRUE, enableScrollWheel = TRUE, mapType = "hybrid", useMapTypeControl = TRUE))

print(AndrewMap, "chart")
```

**check**
```{r fig.width=7, fig.height=6}
## Table with embedded links
PopTable <- gvisTable(Population, options = list(width = 600, height = 300, 
    page = "enable"))

print(PopTable, "chart")
```



